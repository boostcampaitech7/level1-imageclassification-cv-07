{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets.custom_dataset import CustomDataset\n",
    "from datasets.transform import TransformSelector\n",
    "from models.model_selector import ModelSelector\n",
    "from utils.train_utils import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 63 (3701377864.py, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 68\u001b[0;36m\u001b[0m\n\u001b[0;31m    avg_loss = total_loss / total_batches\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 63\n"
     ]
    }
   ],
   "source": [
    "# 추론(inference) 함수\n",
    "def inference(model, device, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader, desc=\"Inference\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# 'best_model' 파일을 찾는 함수 (가장 최근에 저장된 파일 선택)\n",
    "def get_best_model_path(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.startswith('best_model') and f.endswith('.pt')]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No best model files found in directory: {directory}\")\n",
    "    \n",
    "    # 파일의 수정 시간을 기준으로 가장 최근에 저장된 파일 선택\n",
    "    best_file = max(files, key=lambda f: os.path.getmtime(os.path.join(directory, f)))\n",
    "    return os.path.join(directory, best_file)\n",
    "\n",
    "def validate(model, device, val_loader):\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss(label_smoothing=0.08)\n",
    "        total_batches = len(val_loader)\n",
    "        \n",
    "        progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, targets, indices) in enumerate(progress_bar):\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                \n",
    "                # 모델 예측\n",
    "                outputs = model(images)\n",
    "                outputs_softmax = torch.nn.functional.softmax(outputs)\n",
    "                \n",
    "                # 손실 계산\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # 정확도 계산\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "                progress_bar.set_postfix({'val_batch_loss': loss.item()})\n",
    "\n",
    "                # 이미지 그리기\n",
    "                top_fives, top_fives_indices = torch.topk(outputs_softmax, 5)\n",
    "\n",
    "                images = images.cpu().numpy()\n",
    "                targets = targets.cpu().numpy()\n",
    "                indices = indices.cpu().numpy()\n",
    "                outputs_softmax = outputs_softmax.cpu().numpy()\n",
    "                top_fives = top_fives.cpu().numpy()\n",
    "                top_fives_indices = top_fives_indices.cpu().numpy()\n",
    "\n",
    "                for i, index in enumerate(indices):\n",
    "                     \n",
    "\n",
    "        \n",
    "        # 검증의 평균 손실과 정확도 계산\n",
    "        avg_loss = total_loss / total_batches\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"Validation Epoch Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from /data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/results/coatnet_2_rw_224_1/best_model_1.2901.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimmModel(\n",
       "  (model): MaxxVit(\n",
       "    (stem): Stem(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm1): BatchNormAct2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Identity()\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): TransformerBlock2d(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (norm1): Sequential(\n",
       "              (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "              (down): Downsample2d(\n",
       "                (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (expand): Identity()\n",
       "              )\n",
       "            )\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (12): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (13): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): TransformerBlock2d(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (norm1): Sequential(\n",
       "              (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (down): Downsample2d(\n",
       "                (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (expand): Identity()\n",
       "              )\n",
       "            )\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=1024, out_features=500, bias=True)\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = r\"/data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/config_dj1.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "  config = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_info = pd.read_csv(config['data_info_file'])\n",
    "\n",
    "py_dir_path = r\"/data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/Model/0921_valid_analysis\"\n",
    "rel_train_index_path = r\"datasets/train_index.csv\"\n",
    "rel_val_index_path = r\"datasets/val_index.csv\"\n",
    "\n",
    "train_index_path = os.path.join(py_dir_path, rel_train_index_path)\n",
    "val_index_path = os.path.join(py_dir_path, rel_val_index_path)\n",
    "\n",
    "# train_index.csv와 val_index.csv를 이용하여 train_df와 val_df를 로드       \n",
    "train_index = pd.read_csv(train_index_path, header = None).squeeze()\n",
    "val_index = pd.read_csv(val_index_path, header = None).squeeze()\n",
    "\n",
    "train_df = train_info.loc[train_index]\n",
    "val_df = train_info.loc[val_index]\n",
    "\n",
    "transform_selector = TransformSelector(transform_type=\"albumentations\")\n",
    "val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "val_dataset = CustomDataset(root_dir=config['train_data_dir'], info_df=val_df, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "# 모델 설정\n",
    "model_selector = ModelSelector(model_type=\"timm\", num_classes=config['num_classes'], model_name=config['model_name'], pretrained=False)\n",
    "model = model_selector.get_model()\n",
    "\n",
    "# 베스트 모델 경로 설정\n",
    "model_path = get_best_model_path(config['result_path'])\n",
    "print(f\"Loading best model from {model_path}\")\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 추론 실행\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, device, val_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(model, device, val_loader):\n\u001b[0;32m---> 24\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     25\u001b[0m         total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     26\u001b[0m         correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, device, val_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(model, device, val_loader):\n\u001b[0;32m---> 24\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     25\u001b[0m         total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     26\u001b[0m         correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 추론 실행\n",
    "validate(model, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]/tmp/ipykernel_504701/2645326558.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_softmax = torch.nn.functional.softmax(outputs)\n",
      "Validating:   1%|          | 1/94 [00:00<00:26,  3.46it/s, val_batch_loss=1.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   2%|▏         | 2/94 [00:00<00:26,  3.48it/s, val_batch_loss=1.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   3%|▎         | 3/94 [00:00<00:25,  3.52it/s, val_batch_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   4%|▍         | 4/94 [00:01<00:25,  3.56it/s, val_batch_loss=1.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   5%|▌         | 5/94 [00:01<00:24,  3.56it/s, val_batch_loss=1.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   6%|▋         | 6/94 [00:01<00:24,  3.54it/s, val_batch_loss=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   7%|▋         | 7/94 [00:01<00:24,  3.62it/s, val_batch_loss=1.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   9%|▊         | 8/94 [00:02<00:23,  3.60it/s, val_batch_loss=1.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  10%|▉         | 9/94 [00:02<00:23,  3.58it/s, val_batch_loss=1.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  11%|█         | 10/94 [00:02<00:23,  3.62it/s, val_batch_loss=1.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  12%|█▏        | 11/94 [00:03<00:23,  3.56it/s, val_batch_loss=1.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  13%|█▎        | 12/94 [00:03<00:23,  3.56it/s, val_batch_loss=1.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  14%|█▍        | 13/94 [00:03<00:24,  3.33it/s, val_batch_loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  15%|█▍        | 14/94 [00:04<00:23,  3.35it/s, val_batch_loss=1.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  16%|█▌        | 15/94 [00:04<00:23,  3.33it/s, val_batch_loss=1.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  17%|█▋        | 16/94 [00:04<00:23,  3.31it/s, val_batch_loss=1.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  18%|█▊        | 17/94 [00:04<00:23,  3.34it/s, val_batch_loss=1.2] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  19%|█▉        | 18/94 [00:05<00:24,  3.13it/s, val_batch_loss=1.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  20%|██        | 19/94 [00:05<00:23,  3.18it/s, val_batch_loss=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  21%|██▏       | 20/94 [00:05<00:22,  3.32it/s, val_batch_loss=1.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  22%|██▏       | 21/94 [00:06<00:21,  3.42it/s, val_batch_loss=1.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  23%|██▎       | 22/94 [00:06<00:20,  3.48it/s, val_batch_loss=1.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  24%|██▍       | 23/94 [00:06<00:20,  3.54it/s, val_batch_loss=1.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  26%|██▌       | 24/94 [00:06<00:20,  3.41it/s, val_batch_loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  27%|██▋       | 25/94 [00:07<00:20,  3.39it/s, val_batch_loss=1.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  28%|██▊       | 26/94 [00:07<00:19,  3.40it/s, val_batch_loss=1.2] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  29%|██▊       | 27/94 [00:07<00:19,  3.38it/s, val_batch_loss=1.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  30%|██▉       | 28/94 [00:08<00:19,  3.41it/s, val_batch_loss=1.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  31%|███       | 29/94 [00:08<00:18,  3.51it/s, val_batch_loss=1.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  32%|███▏      | 30/94 [00:08<00:18,  3.53it/s, val_batch_loss=1.44]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  33%|███▎      | 31/94 [00:09<00:18,  3.46it/s, val_batch_loss=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  34%|███▍      | 32/94 [00:09<00:18,  3.39it/s, val_batch_loss=1.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  35%|███▌      | 33/94 [00:09<00:17,  3.42it/s, val_batch_loss=1.3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  36%|███▌      | 34/94 [00:09<00:17,  3.45it/s, val_batch_loss=1.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  37%|███▋      | 35/94 [00:10<00:17,  3.46it/s, val_batch_loss=1.32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  38%|███▊      | 36/94 [00:10<00:16,  3.41it/s, val_batch_loss=1.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  39%|███▉      | 37/94 [00:10<00:16,  3.41it/s, val_batch_loss=1.01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 38/94 [00:11<00:16,  3.48it/s, val_batch_loss=1.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  41%|████▏     | 39/94 [00:11<00:15,  3.53it/s, val_batch_loss=1.4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(val_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, targets, indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar):\n\u001b[1;32m     13\u001b[0m         images, targets \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# 모델 예측\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Dongjin/git/level1-imageclassification-cv-07/Model/0921_valid_analysis/datasets/custom_dataset.py:23\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     22\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[index])\n\u001b[0;32m---> 23\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     25\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.08)\n",
    "total_batches = len(val_loader)\n",
    "\n",
    "progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, targets, indices) in enumerate(progress_bar):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # 모델 예측\n",
    "        outputs = model(images)\n",
    "        outputs_softmax = torch.nn.functional.softmax(outputs)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix({'val_batch_loss': loss.item()})\n",
    "\n",
    "        # 이미지 그리기\n",
    "        top_fives, top_fives_indices = torch.topk(outputs_softmax, 5)\n",
    "\n",
    "        images = images.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        indices = indices.cpu().numpy()\n",
    "        outputs_softmax = outputs_softmax.cpu().numpy()\n",
    "        top_fives = top_fives.cpu().numpy()\n",
    "        top_fives_indices = top_fives_indices.cpu().numpy()\n",
    "        predicted = predicted.cpu().numpy()\n",
    "\n",
    "        for i, index in enumerate(indices):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
