{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets.custom_dataset import CustomDataset\n",
    "from datasets.transform import TransformSelector\n",
    "from models.model_selector import ModelSelector\n",
    "from utils.train_utils import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론(inference) 함수\n",
    "def inference(model, device, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader, desc=\"Inference\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# 'best_model' 파일을 찾는 함수 (가장 최근에 저장된 파일 선택)\n",
    "def get_best_model_path(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.startswith('best_model') and f.endswith('.pt')]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No best model files found in directory: {directory}\")\n",
    "    \n",
    "    # 파일의 수정 시간을 기준으로 가장 최근에 저장된 파일 선택\n",
    "    best_file = max(files, key=lambda f: os.path.getmtime(os.path.join(directory, f)))\n",
    "    return os.path.join(directory, best_file)\n",
    "\n",
    "def validate(model, device, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.08)\n",
    "    total_batches = len(val_loader)\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets, indices) in enumerate(progress_bar):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            outputs_softmax = torch.nn.functional.softmax(outputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 정확도 계산\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            progress_bar.set_postfix({'val_batch_loss': loss.item()})\n",
    "\n",
    "            # 이미지 그리기\n",
    "            top_fives, top_fives_indices = torch.topk(outputs_softmax, 5)\n",
    "\n",
    "            images = images.cpu().numpy()\n",
    "            targets = targets.cpu().numpy()\n",
    "            indices = indices.cpu().numpy()\n",
    "            outputs_softmax = outputs_softmax.cpu().numpy()\n",
    "            top_fives = top_fives.cpu().numpy()\n",
    "            top_fives_indices = top_fives_indices.cpu().numpy()                    \n",
    "    \n",
    "    # 검증의 평균 손실과 정확도 계산\n",
    "    avg_loss = total_loss / total_batches\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f\"Validation Epoch Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def convert_image_for_display(image):\n",
    "    # neural network를 위한 이미지에서 plt.imshow()를 위한 이미지 변환\n",
    "    # plt.imshow()는 float 데이터에 대해 [0, 1] 구간을 truncate해서 display 하기 때문에 normalization이 필요함\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def create_target_to_category(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(by = ['target'])\n",
    "    groups = df.groupby('target')\n",
    "\n",
    "    target_to_category = {}\n",
    "\n",
    "    for _, group in groups:\n",
    "        target = group.target.values[0]\n",
    "        category = group.category.values[0]\n",
    "        target_to_category[target] = category\n",
    "\n",
    "    return target_to_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from /data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/results/coatnet_2_rw_224_1/best_model_1.2901.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimmModel(\n",
       "  (model): MaxxVit(\n",
       "    (stem): Stem(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm1): BatchNormAct2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Identity()\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): TransformerBlock2d(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (norm1): Sequential(\n",
       "              (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "              (down): Downsample2d(\n",
       "                (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (expand): Identity()\n",
       "              )\n",
       "            )\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (12): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (13): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MaxxVitStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): TransformerBlock2d(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (expand): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (norm1): Sequential(\n",
       "              (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (down): Downsample2d(\n",
       "                (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (expand): Identity()\n",
       "              )\n",
       "            )\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): TransformerBlock2d(\n",
       "            (shortcut): Identity()\n",
       "            (norm1): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention2d(\n",
       "              (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (rel_pos): RelPosBias()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): GELU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=1024, out_features=500, bias=True)\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup = {\n",
    "  \"coatnet\": r\"/data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/config_dj1.json\",\n",
    "  \"ViT\": r\"/data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/config_dj6.json\",\n",
    "  \"resnet\": r\"/data/ephemeral/home/Dongjin/git/level1-imageclassification-cv-07/LV1/config_dj8.json\",\n",
    "  }\n",
    "\n",
    "config_path = setup[\"coatnet\"]\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "  config = json.load(f)\n",
    "\n",
    "config['batch_size'] = 2 # batch size 줄여서 vram 줄이기\n",
    "\n",
    "py_dir_path = os.getcwd()\n",
    "class_to_name_file = os.path.join(py_dir_path, \"result/class/map_clsloc.txt\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_info = pd.read_csv(config['data_info_file'])\n",
    "\n",
    "# class_name으로 category 불러오기\n",
    "class_to_name = pd.read_csv(class_to_name_file, header = None, sep = \" \")\n",
    "class_to_name.columns = [\"class_name\", \"index\", \"category\"]\n",
    "class_to_name = class_to_name.drop([\"index\"], axis = 1)\n",
    "\n",
    "# train_info에 category merge하고 target_to_category 만들기\n",
    "train_info = pd.merge(train_info, class_to_name, on = 'class_name', how = 'left')\n",
    "target_to_category = create_target_to_category(train_info)\n",
    "\n",
    "rel_train_index_path = r\"datasets/train_index.csv\"\n",
    "rel_val_index_path = r\"datasets/val_index.csv\"\n",
    "\n",
    "train_index_path = os.path.join(py_dir_path, rel_train_index_path)\n",
    "val_index_path = os.path.join(py_dir_path, rel_val_index_path)\n",
    "\n",
    "# train_index.csv와 val_index.csv를 이용하여 train_df와 val_df를 로드       \n",
    "train_index = pd.read_csv(train_index_path, header = None).squeeze()\n",
    "val_index = pd.read_csv(val_index_path, header = None).squeeze()\n",
    "\n",
    "train_df = train_info.loc[train_index]\n",
    "val_df = train_info.loc[val_index]\n",
    "\n",
    "transform_selector = TransformSelector(transform_type=\"albumentations\")\n",
    "val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "val_dataset = CustomDataset(root_dir=config['train_data_dir'], info_df=val_df, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "# 모델 설정\n",
    "model_selector = ModelSelector(model_type=\"timm\", num_classes=config['num_classes'], model_name=config['model_name'], pretrained=False)\n",
    "model = model_selector.get_model()\n",
    "\n",
    "# 베스트 모델 경로 설정\n",
    "model_path = get_best_model_path(config['result_path'])\n",
    "print(f\"Loading best model from {model_path}\")\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(model_name, images, targets, dataset_indices, outputs_softmax, top_fives, top_fives_indices, predicts):\n",
    "    correct_save_fold = f'result/{model_name}/correct'\n",
    "    wrong_save_fold = f'result/{model_name}/wrong'\n",
    "    class_image_dir = os.path.join(py_dir_path, \"result/class\")\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        image = images[i]\n",
    "        target = targets[i]\n",
    "        dataset_index = dataset_indices[i] \n",
    "        output_softmax = outputs_softmax[i]\n",
    "        top_five = top_fives[i]\n",
    "        top_fives_index = top_fives_indices[i]\n",
    "        predict = predicts[i]\n",
    "        iscorrect = target == predict\n",
    "        \n",
    "        img_rel_path = train_info['image_path'].loc[dataset_index]\n",
    "        img_path = os.path.join(config['train_data_dir'], img_rel_path)\n",
    "        class_name = train_info['class_name'].loc[dataset_index]\n",
    "\n",
    "        imag_target_path = os.path.join(class_image_dir, f'{target}.png')\n",
    "        imag_pred_path = os.path.join(class_image_dir, f'{predict}.png')\n",
    "\n",
    "        if iscorrect:\n",
    "            fig, axes = plt.subplots(1, 3, figsize = (15, 6))\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, 4, figsize = (20, 6))\n",
    "\n",
    "        image_origin = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image_origin = cv2.cvtColor(image_origin, cv2.COLOR_BGR2RGB)\n",
    "        image_input = convert_image_for_display(image) # network input image\n",
    "        \n",
    "        image_target = cv2.cvtColor(cv2.imread(imag_target_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "        image_predict = cv2.cvtColor(cv2.imread(imag_pred_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        axes[0].imshow(image_origin)\n",
    "        axes[1].imshow(image_input)\n",
    "        axes[2].imshow(image_target)\n",
    "\n",
    "        axes[0].set_title(\"Origin\")\n",
    "        axes[1].set_title(\"Common transformation\")\n",
    "        axes[2].set_title(f\"Target: {target} ({target_to_category[target]})\")\n",
    "\n",
    "        if not iscorrect:\n",
    "            axes[3].imshow(image_predict)\n",
    "            axes[3].set_title(f\"Predict: {predict} ({target_to_category[predict]})\")\n",
    "\n",
    "        for i in range(len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        # title 만들기\n",
    "        if iscorrect == True:\n",
    "            title0 = f\"{model_name} - Correct\\ntarget: {target} ({target_to_category[target]}), predict: {predict} ({target_to_category[predict]})\"\n",
    "        else:\n",
    "            title0 = f\"{model_name} - Wrong\\ntarget: {target} ({target_to_category[target]}), predict: {predict} ({target_to_category[predict]})\"\n",
    "\n",
    "        title1 = \"\"\n",
    "        for index, prob in zip(top_fives_index, top_five * 100):\n",
    "            if (title1 == \"\"):\n",
    "                title1 = f\"Top 5 - {index}: {prob:.1f}%\"\n",
    "            else:\n",
    "                title1 = title1 + \", \" + f\"{index}: {prob:.1f}%\"\n",
    "\n",
    "        title = f\"{title0}\\n{title1}\\n{img_rel_path}\"\n",
    "        plt.suptitle(title)\n",
    "\n",
    "        # 저장하기\n",
    "\n",
    "        if iscorrect:\n",
    "            save_path = os.path.join(correct_save_fold, f\"{target}/{dataset_index}.png\")\n",
    "        else:\n",
    "            save_path = os.path.join(wrong_save_fold, f\"{target}/{dataset_index}.png\")\n",
    "\n",
    "        if not os.path.isdir(os.path.split(save_path)[0]):\n",
    "            os.makedirs(os.path.split(save_path)[0])\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.tight_layout()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/376 [00:00<?, ?it/s]/tmp/ipykernel_577780/1984756856.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_softmax = torch.nn.functional.softmax(outputs)\n",
      "Validating:   1%|          | 2/376 [00:10<31:08,  4.99s/it, val_batch_loss=0.834]/tmp/ipykernel_577780/2241228335.py:24: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axes = plt.subplots(1, 3, figsize = (15, 6))\n",
      "                                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m top_fives_indices \u001b[38;5;241m=\u001b[39m top_fives_indices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     39\u001b[0m predicts \u001b[38;5;241m=\u001b[39m predicts\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutputs_softmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_fives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_fives_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(model_name, images, targets, dataset_indices, outputs_softmax, top_fives, top_fives_indices, predicts)\u001b[0m\n\u001b[1;32m     30\u001b[0m image_input \u001b[38;5;241m=\u001b[39m convert_image_for_display(image) \u001b[38;5;66;03m# network input image\u001b[39;00m\n\u001b[1;32m     32\u001b[0m image_target \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(imag_target_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 33\u001b[0m image_predict \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimag_pred_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     35\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(image_origin)\n\u001b[1;32m     36\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(image_input)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.08)\n",
    "total_batches = len(val_loader)\n",
    "\n",
    "progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, targets, dataset_indices) in enumerate(progress_bar):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # 모델 예측\n",
    "        outputs = model(images)\n",
    "        outputs_softmax = torch.nn.functional.softmax(outputs)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        correct += (predicts == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix({'val_batch_loss': loss.item()})\n",
    "\n",
    "        # 이미지 그리기\n",
    "        top_fives, top_fives_indices = torch.topk(outputs_softmax, 5)\n",
    "\n",
    "        images = images.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        dataset_indices = dataset_indices.cpu().numpy()\n",
    "        outputs_softmax = outputs_softmax.cpu().numpy()\n",
    "        top_fives = top_fives.cpu().numpy()\n",
    "        top_fives_indices = top_fives_indices.cpu().numpy()\n",
    "        predicts = predicts.cpu().numpy()\n",
    "\n",
    "        plot(config['model_name'], images, targets, dataset_indices,outputs_softmax, top_fives, top_fives_indices, predicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
